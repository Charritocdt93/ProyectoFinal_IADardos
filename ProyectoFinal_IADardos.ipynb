{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTvUnm6vVNpJU6RGvCsMqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b927d6c310d04484b9789760f00eb2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17176f6057d04aaaa7a563aa8fce7c6f",
              "IPY_MODEL_b16ffad2951e403f91923ac2d03d0de8",
              "IPY_MODEL_07bc70e88738486e8839a609815b39ce"
            ],
            "layout": "IPY_MODEL_0d02376fd62449f0bb38cff4833839fe"
          }
        },
        "17176f6057d04aaaa7a563aa8fce7c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_956d1b827acb492696e21f8c615b8014",
            "placeholder": "​",
            "style": "IPY_MODEL_a6cd2d658b0a4fedae60b37b5202323a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b16ffad2951e403f91923ac2d03d0de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc3fe70681d4b32841cea9d1c43ea80",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_777e4e48adb646d69346eee84062c4cc",
            "value": 2
          }
        },
        "07bc70e88738486e8839a609815b39ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b45fddfd1c66431eb4c3f6e415ad6c04",
            "placeholder": "​",
            "style": "IPY_MODEL_5756d94d80fb4b29bdda56f1df163afc",
            "value": " 2/2 [01:17&lt;00:00, 36.09s/it]"
          }
        },
        "0d02376fd62449f0bb38cff4833839fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956d1b827acb492696e21f8c615b8014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6cd2d658b0a4fedae60b37b5202323a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcc3fe70681d4b32841cea9d1c43ea80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777e4e48adb646d69346eee84062c4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b45fddfd1c66431eb4c3f6e415ad6c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5756d94d80fb4b29bdda56f1df163afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charritocdt93/ProyectoFinal_IADardos/blob/main/ProyectoFinal_IADardos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalaciones"
      ],
      "metadata": {
        "id": "1ceMxj3tKwbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet\n",
        "!pip install xformer --quiet\n",
        "!pip install chromadb --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install accelerate --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install bitsandbytes --quiet\n",
        "!pip install unstructured --quiet\n",
        "!pip install sentence-transformers --quiet"
      ],
      "metadata": {
        "id": "_QSHIBwCLo-t"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importaciones"
      ],
      "metadata": {
        "id": "0q9dCqHFLybw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "\n",
        "from textwrap import fill\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    )\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "from langchain import HuggingFacePipeline\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredMarkdownLoader, UnstructuredURLLoader\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
        "\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "hQTY7I-GL2YU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtener LLM y Entrenarlo"
      ],
      "metadata": {
        "id": "1nWKRMfhMQNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME, torch_dtype=torch.float16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config\n",
        ")\n",
        "\n",
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "generation_config.max_new_tokens = 1024\n",
        "generation_config.temperature = 0.0001\n",
        "generation_config.top_p = 0.95\n",
        "generation_config.do_sample = True\n",
        "generation_config.repetition_penalty = 1.15\n",
        "\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    generation_config=generation_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b927d6c310d04484b9789760f00eb2ab",
            "17176f6057d04aaaa7a563aa8fce7c6f",
            "b16ffad2951e403f91923ac2d03d0de8",
            "07bc70e88738486e8839a609815b39ce",
            "0d02376fd62449f0bb38cff4833839fe",
            "956d1b827acb492696e21f8c615b8014",
            "a6cd2d658b0a4fedae60b37b5202323a",
            "bcc3fe70681d4b32841cea9d1c43ea80",
            "777e4e48adb646d69346eee84062c4cc",
            "b45fddfd1c66431eb4c3f6e415ad6c04",
            "5756d94d80fb4b29bdda56f1df163afc"
          ]
        },
        "id": "i6JCGsJiMWsA",
        "outputId": "507d6380-4cce-4a3b-ecd0-77f0c65abe14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b927d6c310d04484b9789760f00eb2ab"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usar Pipeline de Hugging Face"
      ],
      "metadata": {
        "id": "Jm6kK-d1M_-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(\n",
        "    pipeline=pipeline,\n",
        "    )"
      ],
      "metadata": {
        "id": "yAwg6FeVNG5I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embeddings"
      ],
      "metadata": {
        "id": "Mm9DzsVQTmoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"thenlper/gte-large\",\n",
        "    model_kwargs={\"device\": \"cuda\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},\n",
        ")"
      ],
      "metadata": {
        "id": "PqXdvd7uTrh5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Template"
      ],
      "metadata": {
        "id": "5YqjMjzJT-dW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "[INST] <>\n",
        "Act as a Machine Learning engineer who is teaching high school students.\n",
        "<>\n",
        "\n",
        "{text} [/INST]\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=template,\n",
        ")"
      ],
      "metadata": {
        "id": "Y6kT-9LwUBa0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar Paginas"
      ],
      "metadata": {
        "id": "TdCRpIXwUW2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    \"https://www.versus.es/reglas-de-dardos\",\n",
        "    \"https://www.tododardos.com/reglas-campeonatos/\"\n",
        "]\n",
        "\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "documents = loader.load()\n",
        "\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvwKUTmOUa_g",
        "outputId": "e2c5bba9-6ccd-4547-8516-31e2891b2828"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reducir el numero de chuck"
      ],
      "metadata": {
        "id": "JNbPPcfFUsnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
        "texts_chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "len(texts_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvjaa-toUy30",
        "outputId": "7ef87b65-7af2-4bd1-ce68-3105ada89f42"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingesta de datos"
      ],
      "metadata": {
        "id": "YBbmE9gEU-Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = Chroma.from_documents(texts_chunks, embeddings, persist_directory=\"db\")"
      ],
      "metadata": {
        "id": "2pBOeafnVCuc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Platilla de Consulta"
      ],
      "metadata": {
        "id": "t2rgsf2HVSn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "[INST] <>\n",
        "IADarts te responde:\n",
        "<>\n",
        "\n",
        "{context}\n",
        "\n",
        "{question} [/INST]\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        ")"
      ],
      "metadata": {
        "id": "NIj2f78xVXK8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probar IA"
      ],
      "metadata": {
        "id": "Hc0TbszBNP_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"¿Cuantos dardos se usan para jugar?\"\n",
        "result_ = qa_chain(\n",
        "    query\n",
        ")\n",
        "result = result_[\"result\"].strip()\n",
        "\n",
        "\n",
        "display(Markdown(f\"<b>{query}</b>\"))\n",
        "display(Markdown(f\"<p>{result}</p>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "hHaUPmSbNXH2",
        "outputId": "68e98e18-8e4f-4512-e620-c228c8303940"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>¿Cuantos dardos se usan para jugar?</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<p>Los juegos de dardos son un deporte competitivo donde dos o más jugadores compiten entre sí para obtener el mayor puntaje. En este deporte, se utilizan dardos de madera o plástico y se lanzan desde una distancia fija hacia una diana electrónica. La diana tiene varios sectores de diferentes colores y puntuaciones asignadas a cada uno.\n\nEl objetivo del juego es llegar a un puntaje de 301 o más puntos antes que el otro jugador o equipo. Para lograr esto, los jugadores pueden lanzar dardos individuales o combinados, dependiendo de las reglas del juego.\n\nEn general, se utilizan tres dardos por turno, pero el número de dardos que se utilizan varía según las reglas del juego. Además, los jugadores pueden decidir si quieren lanzar todos sus tres dardos en un solo turno o si preferen lanzarlos individualmente.\n\nLa puntuación se calcula sumando los puntos obtenidos por cada dardo que golpea un sector de la diana. Si un dardo no golpea ningún sector, no se puntúa.\n\nEn algunas variantes del juego, se pueden utilizar diferentes tipos de dardos, como los dardos de metal o los dardos con punterías. También hay diferentes tipos de dianas, como las dianas de madera o las dianas de plástico.\n\nEn conclusion, el número de dardos que se utilizan para jugar varía según las reglas del juego, pero generalmente se utilizan tres dardos por turno.</p>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Follow-Up Q/A"
      ],
      "metadata": {
        "id": "I6-emxOAhyIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_template = \"\"\"Usted es Asistente de IADarts. Dada la\n",
        "siguiente conversación y una pregunta de seguimiento, reformule la pregunta de seguimiento\n",
        "para que sea una pregunta independiente. Al final de la pregunta independiente añade lo siguiente\n",
        "Responda a la pregunta en inglés\". Si no conoce la respuesta, responda \"Lo siento, no tengo suficiente información\".\n",
        "Historial de chat:\n",
        "{chat_history}\n",
        "Entrada de seguimiento: {pregunta}\n",
        "Pregunta independiente:\n",
        "\"\"\"\n",
        "\n",
        "CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_template)\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    memory=memory,\n",
        "    condense_question_prompt=CUSTOM_QUESTION_PROMPT,\n",
        ")\n",
        "\n",
        "query = \"¿Que juegos ahi?\"\n",
        "\n",
        "result_ = qa_chain({\"question\": query})\n",
        "result = result_[\"answer\"].strip()\n",
        "\n",
        "display(Markdown(f\"<b>{query}</b>\"))\n",
        "display(Markdown(f\"<p>{result}</p>\"))"
      ],
      "metadata": {
        "id": "FDkIzbaRhzsa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mensajes en memoria"
      ],
      "metadata": {
        "id": "3lMzPzK-iohP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory.chat_memory.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4pKDRSUitDO",
        "outputId": "d6546f56-8543-4649-fe2d-e2de3611b25e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='¿Que juegos ahi?'),\n",
              " AIMessage(content=' The games mentioned are 501, 701, 901 and 1001. They have the same rules as 301, except that each player starts with 501 points or 701 points, etc. To illustrate the rules, we will use 301.')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio Chat UI"
      ],
      "metadata": {
        "id": "MILhCop9i1MF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def querying(query, history):\n",
        "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "  qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "      llm=llm,\n",
        "      retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "      memory=memory,\n",
        "      condense_question_prompt=CUSTOM_QUESTION_PROMPT,\n",
        "  )\n",
        "\n",
        "  result = qa_chain({\"question\": query})\n",
        "  return result[\"answer\"].strip()"
      ],
      "metadata": {
        "id": "RdQAsCAhi2v-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.ChatInterface(\n",
        "    fn = querying,\n",
        "    chatbot=gr.Chatbot(height=600),\n",
        "    textbox=gr.Textbox(placeholder=\"What is GenAI Ecosystem?\", container=False, scale=7),\n",
        "    title=\"HiberusBot\",\n",
        "    theme=\"soft\",\n",
        "    examples=[\"Why Hiberus has created GenAI Ecosystem?\",\n",
        "              \"What is GenAI Ecosystem?\"],\n",
        "\n",
        "    cache_examples=True,\n",
        "    retry_btn=\"Repetir\",\n",
        "    undo_btn=\"Deshacer\",\n",
        "    clear_btn=\"Borrar\",\n",
        "    submit_btn=\"Enviar\"\n",
        "\n",
        "    )\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "XpuwH5_yi6Ki",
        "outputId": "7f6e7205-38d3-4b7e-9025-c3add41fd6b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching examples at: '/content/gradio_cached_examples/15'\n",
            "Caching example 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching example 2/2\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://9a1ef99f0f1c0935cb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9a1ef99f0f1c0935cb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}